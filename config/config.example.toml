# Global LLM configuration
[llm]
model = "gemini-2.0-flash"
base_url = "https://generativelanguage.googleapis.com/v1beta" # API endpoint URL
api_key = "AIzaSyDaqaJfVTsbdi6wNqM88wjSPHsglATg-Kc"
max_tokens = 32000                  # Maximum number of tokens in the response
temperature = 0.0                      # Controls randomness
allowed_domains = ["example.com", "trusted.org", "additional-domain1.com", "additional-domain2.com", "additional-domain3.com"]  # Allowed domains for ethical scraping
allowed_content_types = ["text/html", "application/pdf", "application/json", "application/xml", "application/zip"]  # Permitted content types
# max_input_tokens = 100000            # Maximum input tokens to use across all requests (set to null or delete this line for unlimited)


# [llm] #OLLAMA:
# api_type = 'ollama'
# model = "llama3.2"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# Optional configuration for specific LLM models
#[llm.vision]
#model = "claude-3-7-sonnet"            # The vision model to use
#base_url = "https://api.openai.com/v1" # API endpoint URL for vision model
#api_key = "sk-..."                     # Your API key for vision model
#max_tokens = 8192                      # Maximum number of tokens in the response
#temperature = 0.0                      # Controls randomness
#allowed_domains = ["example.com", "trusted.org"]  # Allowed domains for ethical scraping
#allowed_content_types = ["text/html", "application/pdf"]  # Permitted content types for vision model

# [llm.vision] #OLLAMA VISION:
# api_type = 'ollama'
# model = "llama3.2-vision"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# Browser automation configuration
[browser]
headless = true  # Run in headless mode by default for scaling
disable_security = true
rate_limit = 50  # Maximum requests per second
respect_robots_txt = true  # Enable robots.txt compliance

# Fallback browser settings
enable_fallback = true  # Enable automatic fallback to browser-use/web-ui when scraping fails
max_fallback_attempts = 3  # Maximum number of fallback attempts before giving up
web_ui_url = "http://localhost:3000"  # URL for the browser-use/web-ui service

# Enhanced web browser settings
stealth_mode = true  # Enable stealth mode to avoid detection
random_delay = true  # Enable random delays to appear more human-like
min_delay = 800  # Minimum delay in milliseconds for random delays
max_delay = 2500  # Maximum delay in milliseconds for random delays
user_agent_rotation = true  # Enable user agent rotation
base_delay = 1.0  # Base delay for exponential backoff retry mechanism
validation_level = "thorough"  # Default validation level for multi-source validation

# Extra arguments to pass to the browser
extra_chromium_args = [
  "--disable-blink-features=AutomationControlled",
  "--force-device-scale-factor=1"
]

# Path to a Chrome instance to use to connect to your normal browser
# e.g. '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
#chrome_instance_path = ""
# Connect to a browser instance via WebSocket
#wss_url = ""
# Connect to a browser instance via CDP
#cdp_url = ""

# Optional configuration, Proxy settings for the browser
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

# Optional configuration, Search settings.
# [search]
# Search engine for agent to use. Default is "Google", can be set to "Baidu" or "DuckDuckGo".
engine = "Google"

# [llm] #OPENROUTER:
# api_type = 'openai'
# model = "openai/gpt-3.5-turbo"
# base_url = "https://openrouter.ai/api/v1"
# api_key = "your-openrouter-api-key"
# max_tokens = 4096
# temperature = 0.7
