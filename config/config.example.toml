# Global LLM configuration
[llm]
model = "gemini-2.0-pro-exp-02-05"            # The LLM model to use
base_url = "https://generativelanguage.googleapis.com/v1beta" # API endpoint URL
api_key = "AIzaSyBfuMOORb6H7s0clpko58Zk1iNoPvCR_sw"                     # Your API key
max_tokens = 8192                      # Maximum number of tokens in the response
temperature = 0.0                      # Controls randomness
# max_input_tokens = 100000            # Maximum input tokens to use across all requests (set to null or delete this line for unlimited)

# You can define model-specific overrides
[llm.gpt4]
model = "gpt-4"
temperature = 0.7

# Browser configuration
[browser]
headless = false  # Set to true for production use
disable_security = true
extra_chromium_args = []
# chrome_instance_path = ""  # Uncomment and set if needed
# wss_url = ""  # Uncomment and set if needed
# cdp_url = ""  # Uncomment and set if needed

# Browser proxy configuration (optional)
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

# Search configuration
[search]
engine = "Google"  # Search engine to use